---
title: "Depression Study"
author: "Alexander Chen"
date: "7/25/2021"
output: 
  rmdformats::readthedown:
    number_sections: T
    code_folding: "hide"
    fig_width: 12
---

```{r setup, include = F}
#Knit default settings
knitr::opts_chunk$set(echo = T, fig.width=8, fig.height=4, warning = F)

#Options
options(scipen = 0, digits = 3)

#Load required packages
if(!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, dplyr, ggplot2, data.table, lubridate, plyr, randomForest, caret, psych, rpart, rpart.plot, xgboost,
               plotROC, usmap, glmnet, plotly, haven, magrittr, Stat2Data, skimr, GGally, rmdformats, prettydoc)
```

```{r Initial: Load, eval = F}
cpes.raw <- as.data.frame(read_sav("data/20240-0001-Data.sav"))
if (file.exists("data/cpes.Rda")) {
  file.remove("data/cpes.Rda")
}
saveRDS(cpes.raw, file = "data/cpes.Rda")
```

<h1>Abstract</h1>
blablabla

<h1>Data Cleaning</h1>

<h2>Naming & Classification</h2>

```{r Dataclean: Naming, eval = T}
cpes.raw <- readRDS("data/cpes.Rda")
cpes.cleaned <- cpes.raw %>% rename(
  "sex" = "V09036",
  "age" = "V07306",
  "region" = "V08992",
  "maritalStatus" = "V08759",
  "weightClass" = "V08823",
  "height.inches" = "V06728",
  "race" = "RANCEST",
  "householdIncome" = "V08683",
  "timesMarried" = "V09402",
  "yearsOfEducation.respondent" = "V03085",
  "parents.USBorn" = "V03125",
  "yearsOfEducation.father" = "V03081",
  "yearsOfEducation.mother" = "V03084",
  "employment.initialAge" = "V09390",
  "employment.current" = "V09154",
  
  #Adult Demographics
  "homeless.historical" = "V05633",
  "relativeWellOffRank.usPop" = "V05668",
  "relativeWellOffRank.local" = "V05669",
  "religiousAttendance.freq" = "V05629",
  "motherAlive" = "V05672",
  "motherDeath.respondentAge" = "V05674",
  "fatherAlive" = "V05686",
  "fatherDeath.respondentAge" = "V05689",
  
  #Childhood Demographics
  "highschool.numAttended" = "V05732",
  "districtHadMiddleSchool" = "V05733",
  "gradeSchool.relativeAge" = "V05741",
  "religiousImportance.childhood" = "V05713",
  "familyHeadWorkTime.male" = "V05814",
  "familyHeadWorkTime.female" = "V05820",
  "neglect.insuffSupervision" = "V05836",
  "neglect.dangerousChores" = "V05835",
  "neglect.parentSpendOnSelf" = "V05837",
  "neglect.hunger" = "V05838",
  "neglect.insuffMedical" = "V05839",
  "femaleCaretaker.closeness" = "V05841",
  "femaleCaretaker.strictRules" = "V05845",
  "femaleCaretaker.depression" = "V05846",
  "femaleCaretaker.depression.hospitalized" = "V05850",
  "femaleCaretaker.anxiety" = "V05852",
  "femaleCaretaker.employmentDifficulty" = "V05865",
  "femaleCaretaker.physicalFights" = "V05867",
  "femaleCaretaker.crime" = "V05868",
  "femaleCaretaker.suicideAttempt" = "V05871",
  "maleCaretaker.closeness" = "V05874",
  "maleCaretaker.strictRules" = "V05878",
  "maleCaretaker.depression" = "V05879",
  "maleCaretaker.depression.hospitalized" = "V05883",
  "maleCaretaker.anxiety" = "V05885",
  "maleCaretaker.employmentDifficulty" = "V05900",
  "maleCaretaker.physicalFights" = "V05902",
  "maleCaretaker.crime" = "V05903",
  "maleCaretaker.suicideAttempt" = "V05906",
  
  #Temporal
  "physicalHealth.30day" = "V04445",
  "healthWorkAbsence.30day" = "V04452",
  "difficultyConcentrating.30day" = "V04469",
  "difficultyUnderstandingSituation.30day" = "V04470",
  "difficutlyRemembering.30day" = "V04471",
  "daysMobilityDifficult.30day" = "V04474",
  "socialLifeDifficulty.30day" = "V04483",
  "daysOvertime.30day" = "V05219",
  "jobPerformance.30day" = "V05239",
  
  #Discrimination
  "lessRespect.freq" = "V06539",
  "nameCalled.freq" = "V06545",
  "dislikedForRace" = "V06550",
  
  #Employment
  "wksUnemployed.12month" = "V05162",
  "workHrs.week" = "V05204",
  
  #Family Burden
  "closeFamily.alive" = "V06280",
  "closeRelative.cancer" = "V06282",
  "closeRelative.seriousHeartProblem" = "V06290",
  "closeRelative.seriousMemoryProblem" = "V06298",
  "closeRelative.depression" = "V06344",
  "closeRelative.anxiety" = "V06352",
  
  #Family Cohesion
  "family.respectEachother" = "V06523",
  "proudOfFamily" = "V06528",
  "family.enjoyTogetherFreeTime" = "V06530",
  "family.closenessHindersPersonalGoals" = "V06533",
  "family.argueCustoms" = "V06534",
  
  #Finances
  "finances.numberPplSupportingHousehold" = "V05315",
  "afterLiquidationAndDebts.balance" = "V05312",
  "financialNeedsMet" = "V05321",
  "monthlyBillDifficulty" = "V05322",
  "insuffFoodMoney.prevYear" = "V05325",
  
  #Gambling
  "gamble.totalCount" = "V04950",
  "gamble.ageFirstExposure" = "V04962",
  
  #Marriage
  "marriage.divorceAnnulmentCount" = "V09403",
  "marriage.regretMarriage" = "V05380",
  "spouse.tooMuchAlcoholDrugs" = "V05406",
  "spouse.jobDifficulty" = "V05415",
  "spouse.financeDisagreement" = "V05373",
  "spouse.lifePhilosophyDisagreement" = "V05376",
  "spouse.majorDecisionDisagreement" = "V05377",
  "spouse.quarrel" = "V05379",
  
  #Personality
  "personality.transparentFeelings" = "V03232",
  "personality.indecisiveAbtSelfPath" = "V03240",
  "personality.feelBadWhenHurtAnother" = "V03243",
  "personality.willLieToAchieveGoal" = "V03245",
  "personality.takeRiskyChances" = "V03247",
  "personality.argueWhenStopped" = "V03252",
  "personality.letOthersMakeBigDecisions" = "V03255",
  "personality.dislikeAlone" = "V03256",
  "personality.askAdviceAbtEverydayDecisions" = "V03257",
  "personality.sociallyAwkward" = "V03261",
  "personality.preferSoloActivities" = "V03263",
  "personality.easyToGetCloseToOthers" = "V05514",
  
  #Screening
  "cigsPerDay" = "V04601",
  
  #Neighborhood
  "neighborhood.trustworthy" = "V06497",
  "neighborhood.nightSafety" = "V06501",
  
  #Social Networks
  "freqTalkWithRelatives" = "V05501",
  "freqArgueWithRelatives" = "V05505",
  "freqFriendInteraction" = "V05506",
  "freqTransparentPersonalProblems" = "V05513",
  
  ##DX: Major Depressive Disorder
  "depression.lifetime" = "V07876",
  "depression.12Month" = "V07655",
  "depression.30day" = "V07657",
  "depression.onset" = "V08766",
  "depression.recency" = "V08768"
)
```

Important variables were selected and renamed according to official documentation (found in the same folder as the raw data .sav file after downloading from this site: LINK)<br>

Additionally, categorical and continuous variables were converted to factors and doubles respectively, for compatibility with later algorithms.<br>

Categorical variables and continuous variables are listed below:<br>

##Var List##
**Categorical (Refer to Appendix for Detailed Breakdown of Variable Categories):**<br>
Current Employment Status (Time of Survey)<br>
Marital Status (Time of Survey)<br>
Mother Alive (Time of Survey)<br>
Father Alive (Time of Survey)<br>
Financial Stability After Liquidating and Paying Debts (Time of Survey)<br>
Physical Health (Past 30 Days)<br>
Difficulty Concentrating (Past 30 Days)<br>
Difficulty Understanding Situations (Past 30 Days)<br>
Difficulty Remembering (Past 30 Days)<br>
Social Life Difficulty (Past 30 Days)<br>
Financial Needs Met (Past Year)<br>
Monthly Bill Difficulty (Past Year)<br>
Freq Insufficient Money for Food (Past Year)<br>
Spouse Takes Too Much Alcohol/Drugs (Past Year)<br>
Spouse Has Trouble Finding Job (Past Year)<br>
Freq Talk With Relatives (Past Year)<br>
Freq Argue With Relatives (Past Year)<br>
Freq Interact With Friends (Past Year)<br>
Freq Transparent With Personal Problems (Past Year)<br>
Homeless (Past or Present)<br>
Trustworthy Neighborhood (Past Year)<br>
Neighborhood Safe At Night (Past Year)<br>
Family Mutual Respect (Past Year)<br>
Proud of Family (Past Year)<br>
Family Enjoys Free Time Together (Past Year)<br>
Family Closeness Obstructs Personal Goals (Past Year)<br>
Family Argues Customs (Past Year)<br>
Freq Less Respect vs. Peers (Past Year)<br>
Freq Name Called (Past Year)<br>
Freq Disliked for Race (Past Year)<br>
Weight Class (Past Year)<br>
Freq Attend Church (Past Year)<br>
Freq Disagree With Spouse on Finances (Past Year)<br>
Freq Disagree With Spouse on Life Philosophy<br>
Freq Disagree With Spouse on Major Decisions (Past Year)<br>
Freq Quarrel with Spouse (Past Year)<br>
Freq Regret Marriage (Past Year)<br>
Close Relative has Cancer (Past Year)<br>
Close Relative has Serious Heart Problem (Past Year)<br>
Close Relative has Serious Memory Problem (Past Year)<br>
Close Relative has Depression (Past Year)<br>
Close Relative has Anxiety (Past Year)<br>
District Had Middle School (Childhood)<br>
Relative Age During Grade School (Childhood)<br>
Religious Importance (Childhood)<br>
Male Head Time Spend At Work (Childhood)<br>
Female Head Time Spend At Work (Childhood)<br>
Freq Doing Dangerous Chores (Childhood)<br>
Freq Insufficiently Supervised (Childhood)<br>
Freq Parent Neglected Respondent and Spent on Self (Childhood)<br>
Freq Hungry Due To Neglect (Childhood)<br>
Freq Insufficient Medical Care (Childhood)<br>
Closeness to Female Caretaker (Childhood)<br>
Female Caretaker had Strict Rules (Childhood)<br>
Female Caretaker had Depression (Childhood)<br>
Female Caretaker Hospitalized for Depression (Childhood)<br>
Female Caretaker had Anxiety (Childhood)<br>
Female Caretaker had Difficulty Finding Job (Childhood)<br>
Female Caretaker had Physical Fights (Childhood)<br>
Female Caretaker Engaged in Crime (Childhood)<br>
Female Caretaker Attempted Suicide (Childhood)<br>
Closeness to Male Caretaker (Childhood)<br>
Male Caretaker had Strict Rules (Childhood)<br>
Male Caretaker had Depression (Childhood)<br>
Male Caretaker Hospitalized for Depression (Childhood)<br>
Male Caretaker had Anxiety (Childhood)<br>
Male Caretaker had Difficulty Finding Job (Childhood)<br>
Male Caretaker had Physical Fights (Childhood)<br>
Male Caretaker Engaged in Crime (Childhood)<br>
Male Caretaker Attempted Suicide (Childhood)<br>
Transparent Personality<br>
Indecisive About Own Future<br>
Feel Bad When Harm Another<br>
Will Lie to Achieve Goals<br>
Take Risks<br>
Argue When Stopped<br>
Let Others Make Big Decisions<br>
Dislike Isolation<br>
Ask Advice About Everyday Decisions<br>
Easy to Get Close to Others<br>
Socially Awkward<br>
Prefer Solo Activities<br>
Race<br>
Sex<br>
Region (US Census)<br>

**Continuous:**<br>
Age (Time of Survey)<br>
Height (Time of Survey)<br>
Number of People Financially Supporting Household (Time of Survey)<br>
Health Related Work Absence (Past 30 Days)<br>
Difficult Mobility (Past 30 Days)<br>
Worked Overtime (Past 30 Days)<br>
Job Performance (Past 30 Days)<br>
Relative Well Being vs. USPop (Past Year)<br>
Relative Well Being vs. Neighborhood (Past Year)<br>
Work Hrs per Week (Past Year)<br>
Household Income (Past Year)<br>
Weeks Unemployed (Past Year)<br>
Cigarettes per Day (Past Year)<br>
Times Married<br>
Number of Divorce/Annulments<br>
Years of Education<br>
Times Gambled<br>
Age First Exposed to Gambling<br>
Age at Time of Mother's Death<br>
Age at Time of Father's Death<br>
High-schools Attended<br>
US Born Parents<br>
Alive Close Family<br>
Father Years of Education<br>
Mother Years of Education<br>
Age First Employed<br>
##Var List End##

<h2> Factoring and Subsetting </h2>

```{r Dataclean: Factoring, eval = T}
#Convert appropriate variables to factor
cpes.cleaned %<>% mutate_at(
  c("sex", "region", "maritalStatus","weightClass", "race", "employment.current", "physicalHealth.30day", "difficultyConcentrating.30day", "difficultyUnderstandingSituation.30day", "difficutlyRemembering.30day", "socialLifeDifficulty.30day", "afterLiquidationAndDebts.balance", "spouse.tooMuchAlcoholDrugs", "financialNeedsMet","monthlyBillDifficulty","insuffFoodMoney.prevYear", "spouse.jobDifficulty", "freqTalkWithRelatives", "freqArgueWithRelatives", "freqFriendInteraction", "freqTransparentPersonalProblems", "homeless.historical", "neighborhood.trustworthy", "neighborhood.nightSafety", "family.respectEachother", "proudOfFamily", "family.enjoyTogetherFreeTime", "family.closenessHindersPersonalGoals", "family.argueCustoms", "lessRespect.freq", "nameCalled.freq", "dislikedForRace", "religiousAttendance.freq", "personality.transparentFeelings", "personality.indecisiveAbtSelfPath", "personality.feelBadWhenHurtAnother", "personality.willLieToAchieveGoal", "personality.takeRiskyChances", "personality.argueWhenStopped", "personality.letOthersMakeBigDecisions", "personality.dislikeAlone", "personality.askAdviceAbtEverydayDecisions", "personality.sociallyAwkward", "personality.preferSoloActivities", "spouse.financeDisagreement", "spouse.lifePhilosophyDisagreement", "spouse.majorDecisionDisagreement", "spouse.quarrel", "marriage.regretMarriage", "personality.easyToGetCloseToOthers", "motherAlive", "fatherAlive", "districtHadMiddleSchool", "gradeSchool.relativeAge", "religiousImportance.childhood", "familyHeadWorkTime.male", "familyHeadWorkTime.female", "neglect.dangerousChores", "neglect.insuffSupervision", "neglect.parentSpendOnSelf", "neglect.hunger", "neglect.insuffMedical", "femaleCaretaker.closeness", "femaleCaretaker.strictRules", "femaleCaretaker.depression", "femaleCaretaker.depression.hospitalized", "femaleCaretaker.anxiety", "femaleCaretaker.employmentDifficulty", "femaleCaretaker.physicalFights", "femaleCaretaker.crime", "femaleCaretaker.suicideAttempt", "maleCaretaker.closeness", "maleCaretaker.strictRules", "maleCaretaker.depression", "maleCaretaker.depression.hospitalized", "maleCaretaker.anxiety", "maleCaretaker.employmentDifficulty", "maleCaretaker.physicalFights", "maleCaretaker.crime", "maleCaretaker.suicideAttempt", "closeRelative.cancer", "closeRelative.seriousHeartProblem", "closeRelative.seriousMemoryProblem", "closeRelative.depression", "closeRelative.anxiety", "depression.30day" ,"depression.12Month" ,"depression.lifetime"), as.factor)

#Convert appropriate variables to numeric
cpes.cleaned %<>% mutate_at(
  c("age", "height.inches","householdIncome","timesMarried", "finances.numberPplSupportingHousehold", "wksUnemployed.12month", "marriage.divorceAnnulmentCount", "yearsOfEducation.respondent", "workHrs.week","cigsPerDay","gamble.totalCount", "gamble.ageFirstExposure", "daysOvertime.30day", "motherDeath.respondentAge", "fatherDeath.respondentAge","highschool.numAttended", "closeFamily.alive", "parents.USBorn", "yearsOfEducation.father","yearsOfEducation.mother","employment.initialAge", "jobPerformance.30day", "depression.recency","depression.onset", "healthWorkAbsence.30day", "daysMobilityDifficult.30day", "relativeWellOffRank.usPop", "relativeWellOffRank.local"), as.numeric)
```

```{r factor level naming, eval = F}
cpes.cleaned$employment.current <- recode_factor(cpes.cleaned$employment.current, '1' = "Employed", '2' = "Unemployed", '3' = "Not In Labor Force")
cpes.cleaned$physicalHealth.30day <- recode_factor(cpes.cleaned$physicalHealth.30day, '1' = "Better", '2' = "Worse", '3' = "About The Same")
cpes.cleaned$homeless.historical <- recode_factor(cpes.cleaned$homeless.historical, '1' = "Yes", '5' = "No")
cpes.cleaned$difficultyConcentrating.30day <- recode_factor(cpes.cleaned$difficultyConcentrating.30day, '1' = "None", '2' = "Mild", '3' = "Moderate", '4' = "Severe", '5' = "Impossible")
cpes.cleaned$difficultyUnderstandingSituation.30day <- recode_factor(cpes.cleaned$difficultyUnderstandingSituation.30day, '1' = "None", '2' = "Mild", '3' = "Moderate", '4' = "Severe", '5' = "Impossible")
cpes.cleaned$difficutlyRemembering.30day <- recode_factor(cpes.cleaned$difficutlyRemembering.30day, '1' = "None", '2' = "Mild", '3' = "Moderate", '4' = "Severe", '5' = "Impossible")
cpes.cleaned$socialLifeDifficulty.30day <- recode_factor(cpes.cleaned$socialLifeDifficulty.30day, '1' = "Yes", '5' = "No")
cpes.cleaned$afterLiquidationAndDebts.balance <- recode_factor(cpes.cleaned$afterLiquidationAndDebts.balance, '1' = "Money Left", '2' = "Owe Money", '3' = "Debts Equal Assets", '4' = "Don't Owe Anything")
cpes.cleaned$financialNeedsMet <- recode_factor(cpes.cleaned$financialNeedsMet, '1' = "More Than Need", '2' = "Just Enough", '3' = "Not Enough")
cpes.cleaned$monthlyBillDifficulty <- recode_factor(cpes.cleaned$monthlyBillDifficulty, '1' = "Very Difficult", '2' = "Somewhat Difficult", '3' = "Not Very Difficult", '4' = "Not At All Difficult")
cpes.cleaned$insuffFoodMoney.prevYear <- recode_factor(cpes.cleaned$insuffFoodMoney.prevYear, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$spouse.tooMuchAlcoholDrugs <- recode_factor(cpes.cleaned$spouse.tooMuchAlcoholDrugs, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$spouse.jobDifficulty <- recode_factor(cpes.cleaned$spouse.jobDifficulty, '1' = "Yes", '5' = "No", '7' = "Does Not Apply/Spouse Never Worked")
cpes.cleaned$freqTalkWithRelatives <- recode_factor(cpes.cleaned$freqTalkWithRelatives, '1' = "Most Every Day", '2' = "A Few Times A Week", '3' = "A Few Times A Month", '4' = "Once A Month", '5' = "Less Than Once A Month")
cpes.cleaned$freqArgueWithRelatives <- recode_factor(cpes.cleaned$freqArgueWithRelatives, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$freqFriendInteraction <- recode_factor(cpes.cleaned$freqFriendInteraction, '1' = "Most Every Day", '2' = "A Few Times A Week", '3' = "A Few Times A Month", '4' = "Once A Month", '5' = "Less Than Once A Month")
cpes.cleaned$freqTransparentPersonalProblems <- recode_factor(cpes.cleaned$freqTransparentPersonalProblems, '1' = "Always", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$freqTransparentPersonalProblems <- recode_factor(cpes.cleaned$freqTransparentPersonalProblems, '1' = "Yes", '2' = "No")
cpes.cleaned$neighborhood.trustworthy <- recode_factor(cpes.cleaned$neighborhood.trustworthy, '1' = "Very True", '2' = "Somewhat True", '3' = "Not Very True", '4' = "Not At All True")
cpes.cleaned$neighborhood.nightSafety <- recode_factor(cpes.cleaned$neighborhood.nightSafety, '1' = "Very True", '2' = "Somewhat True", '3' = "Not Very True", '4' = "Not At All True")
cpes.cleaned$family.respectEachother <- recode_factor(cpes.cleaned$family.respectEachother, '1' = "Strongly Agree", '2' = "Somewhat Agree", '3' = "Somewhat Disagree", '4' = "Strongly Disagree")
cpes.cleaned$proudOfFamily <- recode_factor(cpes.cleaned$proudOfFamily, '1' = "Strongly Agree", '2' = "Somewhat Agree", '3' = "Somewhat Disagree", '4' = "Strongly Disagree")
cpes.cleaned$family.enjoyTogetherFreeTime <- recode_factor(cpes.cleaned$family.enjoyTogetherFreeTime, '1' = "Strongly Agree", '2' = "Somewhat Agree", '3' = "Somewhat Disagree", '4' = "Strongly Disagree")
cpes.cleaned$family.closenessHindersPersonalGoals <- recode_factor(cpes.cleaned$family.closenessHindersPersonalGoals, '1' = "Hardly Ever/Never", '2' = "Sometimes", '3' = "Often")
cpes.cleaned$family.argueCustoms <- recode_factor(cpes.cleaned$family.argueCustoms, '1' = "Hardly Ever/Never", '2' = "Sometimes", '3' = "Often")
cpes.cleaned$lessRespect.freq <- recode_factor(cpes.cleaned$lessRespect.freq, '1' = "Almost Every Day", '2' = "At Least Once A Week", '3' = "A Few Times A Month", '4' = "A Few Times A Year", '5' = "Less Than Once A Year", '6' = "Never")
cpes.cleaned$nameCalled.freq <- recode_factor(cpes.cleaned$nameCalled.freq, '1' = "Almost Every Day", '2' = "At Least Once A Week", '3' = "A Few Times A Month", '4' = "A Few Times A Year", '5' = "Less Than Once A Year", '6' = "Never")
cpes.cleaned$dislikedForRace <- recode_factor(cpes.cleaned$dislikedForRace, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$sex <- recode_factor(cpes.cleaned$sex, '1' = "Male", '2' = "Female")
cpes.cleaned$region <- recode_factor(cpes.cleaned$region, '1' = "Northeast", '2' = "Midwest", '3' = "South", '4' = "West")
cpes.cleaned$maritalStatus <- recode_factor(cpes.cleaned$maritalStatus, '1' = "Married/Cohabiting", '2' = "Divorced/Separated/Widowed", '3' = "Never Married")
cpes.cleaned$religiousAttendance.freq <- recode_factor(cpes.cleaned$religiousAttendance.freq, '1' = "More Than Once A Week", '2' = "About Once A Week", '3' = "One To Three Times A Month", '4' = "Less Than Once A Month", '5' = "Never")
cpes.cleaned$weightClass <- recode_factor(cpes.cleaned$weightClass, '1' = "Underweight", '2' = "Healthy", '3' = "Overweight", '4' = "Obesity Class 1", '5' = "Obesity Class 2", '5' = "Obesity Class 3")
cpes.cleaned$race <- recode_factor(cpes.cleaned$race, '1' = "Vietnamese", '2' = "Filipino", '3' = "Chinese", '4' = "All Other Asian", '5' = "Cuban", '6' = "PuertoRican", '7' = "Mexican", '8' = "All Other Hispanic", '9' = "Afro-Carribean", '10' = "African American", '11' = "Non-Hispanic Whites", '12' = "All Other")
cpes.cleaned$personality.transparentFeelings <- recode_factor(cpes.cleaned$personality.transparentFeelings, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.indecisiveAbtSelfPath <- recode_factor(cpes.cleaned$personality.indecisiveAbtSelfPath, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.feelBadWhenHurtAnother <- recode_factor(cpes.cleaned$personality.feelBadWhenHurtAnother, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.willLieToAchieveGoal <- recode_factor(cpes.cleaned$personality.willLieToAchieveGoal, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.takeRiskyChances <- recode_factor(cpes.cleaned$personality.takeRiskyChances, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.letOthersMakeBigDecisions <- recode_factor(cpes.cleaned$personality.letOthersMakeBigDecisions, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.argueWhenStopped <- recode_factor(cpes.cleaned$personality.argueWhenStopped, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.dislikeAlone <- recode_factor(cpes.cleaned$personality.dislikeAlone, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.askAdviceAbtEverydayDecisions <- recode_factor(cpes.cleaned$personality.askAdviceAbtEverydayDecisions, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.sociallyAwkward <- recode_factor(cpes.cleaned$personality.sociallyAwkward, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$personality.preferSoloActivities <- recode_factor(cpes.cleaned$personality.preferSoloActivities, '1' = "TRUE", '5' = "FALSE")
cpes.cleaned$spouse.financeDisagreement <- recode_factor(cpes.cleaned$spouse.financeDisagreement, '1' = "All Of The Time", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$spouse.lifePhilosophyDisagreement <- recode_factor(cpes.cleaned$spouse.lifePhilosophyDisagreement, '1' = "All Of The Time", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$spouse.quarrel <- recode_factor(cpes.cleaned$spouse.quarrel, '1' = "All Of The Time", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$spouse.majorDecisionDisagreement <- recode_factor(cpes.cleaned$spouse.majorDecisionDisagreement, '1' = "All Of The Time", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$marriage.regretMarriage <- recode_factor(cpes.cleaned$marriage.regretMarriage, '1' = "All Of The Time", '2' = "Most Of The Time", '3' = "Sometimes", '4' = "Rarely", '5' = "Never")
cpes.cleaned$personality.easyToGetCloseToOthers <- recode_factor(cpes.cleaned$personality.easyToGetCloseToOthers,  '1' = "Strongly Agree", '2' = "Somewhat Agree", '3' = "Somewhat Disagree", '4' = "Strongly Disagree")
cpes.cleaned$motherAlive <- recode_factor(cpes.cleaned$motherAlive, '1' = "Yes", '5' = "No")
cpes.cleaned$fatherAlive <- recode_factor(cpes.cleaned$fatherAlive, '1' = "Yes", '5' = "No")
cpes.cleaned$gradeSchool.relativeAge <- recode_factor(cpes.cleaned$gradeSchool.relativeAge, '1' = "Younger", '2' = "Older", '3' = "Average", '4' = "Varied")
cpes.cleaned$districtHadMiddleSchool <- recode_factor(cpes.cleaned$districtHadMiddleSchool, '1' = "Yes", '5' = "No")
cpes.cleaned$religiousImportance.childhood <- recode_factor(cpes.cleaned$religiousImportance.childhood, '1' = "Very Important", '2' = "Somewhat Important", '3' = "Not Very Important", '4' = "Not At All Important")
cpes.cleaned$familyHeadWorkTime.female <- recode_factor(cpes.cleaned$familyHeadWorkTime.female, '1' = "All", '2' = "Most", '3' = "Some", '4' = "A Little", '5' = "Not At All")
cpes.cleaned$familyHeadWorkTime.male <- recode_factor(cpes.cleaned$familyHeadWorkTime.male, '1' = "All", '2' = "Most", '3' = "Some", '4' = "A Little", '5' = "Not At All")
cpes.cleaned$neglect.insuffSupervision <- recode_factor(cpes.cleaned$neglect.insuffSupervision, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$neglect.parentSpendOnSelf <- recode_factor(cpes.cleaned$neglect.parentSpendOnSelf, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$neglect.dangerousChores <- recode_factor(cpes.cleaned$neglect.dangerousChores, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$neglect.hunger <- recode_factor(cpes.cleaned$neglect.hunger, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$neglect.insuffMedical <- recode_factor(cpes.cleaned$neglect.insuffMedical, '1' = "Often", '2' = "Sometimes", '3' = "Rarely", '4' = "Never")
cpes.cleaned$femaleCaretaker.closeness <- recode_factor(cpes.cleaned$femaleCaretaker.closeness, '1' = "Very Close", '2' = "Somewhat Close", '3' = "Not Very Close", '4' = "Not At All Close")
cpes.cleaned$femaleCaretaker.strictRules <- recode_factor(cpes.cleaned$femaleCaretaker.strictRules, '1' = "A Lot", '2' = "Some", '3' = "A Little", '4' = "Not At All")
cpes.cleaned$femaleCaretaker.depression.hospitalized <- recode_factor(cpes.cleaned$femaleCaretaker.depression.hospitalized, '1' = "Yes", '5' = "No")
cpes.cleaned$femaleCaretaker.depression <- recode_factor(cpes.cleaned$femaleCaretaker.depression, '1' = "Yes", '5' = "No")
cpes.cleaned$femaleCaretaker.anxiety <- recode_factor(cpes.cleaned$femaleCaretaker.anxiety, '1' = "Yes", '5' = "No")
cpes.cleaned$femaleCaretaker.physicalFights <- recode_factor(cpes.cleaned$femaleCaretaker.physicalFights, '1' = "Yes", '5' = "No")
cpes.cleaned$femaleCaretaker.crime <- recode_factor(cpes.cleaned$femaleCaretaker.crime, '1' = "Yes", '5' = "No")
cpes.cleaned$femaleCaretaker.employmentDifficulty <- recode_factor(cpes.cleaned$femaleCaretaker.employmentDifficulty, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.closeness <- recode_factor(cpes.cleaned$maleCaretaker.closeness, '1' = "Very Close", '2' = "Somewhat Close", '3' = "Not Very Close", '4' = "Not At All Close")
cpes.cleaned$femaleCaretaker.suicideAttempt <- recode_factor(cpes.cleaned$femaleCaretaker.suicideAttempt, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.strictRules <- recode_factor(cpes.cleaned$maleCaretaker.strictRules, '1' = "A Lot", '2' = "Some", '3' = "A Little", '4' = "Not At All")
cpes.cleaned$maleCaretaker.depression.hospitalized <- recode_factor(cpes.cleaned$maleCaretaker.depression.hospitalized, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.depression <- recode_factor(cpes.cleaned$maleCaretaker.depression, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.anxiety <- recode_factor(cpes.cleaned$maleCaretaker.anxiety, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.employmentDifficulty <- recode_factor(cpes.cleaned$maleCaretaker.employmentDifficulty, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.physicalFights <- recode_factor(cpes.cleaned$maleCaretaker.physicalFights, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.crime <- recode_factor(cpes.cleaned$maleCaretaker.crime, '1' = "Yes", '5' = "No")
cpes.cleaned$maleCaretaker.suicideAttempt <- recode_factor(cpes.cleaned$maleCaretaker.suicideAttempt, '1' = "Yes", '5' = "No")
cpes.cleaned$closeRelative.cancer <- recode_factor(cpes.cleaned$closeRelative.cancer, '1' = "Yes", '5' = "No")
cpes.cleaned$closeRelative.seriousHeartProblem <- recode_factor(cpes.cleaned$closeRelative.seriousHeartProblem, '1' = "Yes", '5' = "No")
cpes.cleaned$closeRelative.seriousMemoryProblem <- recode_factor(cpes.cleaned$closeRelative.seriousMemoryProblem, '1' = "Yes", '5' = "No")
cpes.cleaned$closeRelative.depression <- recode_factor(cpes.cleaned$closeRelative.depression, '1' = "Yes", '5' = "No")
cpes.cleaned$closeRelative.anxiety <- recode_factor(cpes.cleaned$closeRelative.anxiety, '1' = "Yes", '5' = "No")

cpes.cleaned$depression.lifetime <- recode_factor(depression$depression.lifetime, '1' = "Endorsed", '5' = "Not Endorsed")
cpes.cleaned$depression.12Month <- recode_factor(depression$depression.12Month, '1' = "Endorsed", '5' = "Not Endorsed")
cpes.cleaned$depression.30day <- recode_factor(depression$depression.30day, '1' = "Endorsed", '5' = "Not Endorsed")
```

We subset our data into separate data-frames of categorical and continuous variables for ease of use. We also rename factor levels accordingly.

<h2> Extraneous Data Removal </h2>

```{r extraneous data removal, eval = T}
if("SESTRAT" %in% names(cpes.cleaned)){
  cpes.cleaned <- cpes.cleaned %>% select(-starts_with("V") & -starts_with("NC") & -starts_with("NS") & -starts_with("NL") & -starts_with("CPES") & -c("SESTRAT", "SECLUSTR"))
}
cpes.cleaned$householdIncome[cpes.cleaned$householdIncome < 10000] <- NA
cpes.cleaned$parents.USBorn <- cpes.cleaned$parents.USBorn - rep(1, nrow(cpes.cleaned))
cpes.cleaned$employment.initialAge[cpes.cleaned$employment.initialAge > cpes.cleaned$age] <- NA
cpes.cleaned$fatherDeath.respondentAge[cpes.cleaned$fatherDeath.respondentAge > cpes.cleaned$age] <- NA
cpes.cleaned$motherDeath.respondentAge[cpes.cleaned$motherDeath.respondentAge > cpes.cleaned$age] <- NA
cpes.cleaned$closeFamily.alive[cpes.cleaned$closeFamily.alive > 25] <- NA
```

Extraneous or unusual data is either modified or removed.<br>
Annual household incomes below 10,000 are removed, as there is high likelihood they are typos.<br>
US Born Parent variable values are mutated to be one less than their original value so numeric values now align with number of US born parents.<br>
Initial employment age, respondent age at mother's death, and respondent age at father's death are all removed if the value is greater than respondent's current age.
Alive close family values above 25 are removed. Respondents likely did not interpret close family as commonly accepted.<br>

<h1>Exploratory Data Analysis</h1>
We conduct a brief EDA, looking at surface level trends in depression rate for region, sex, age, race, income, employment, and education

<h2>Region</h2>

```{r EDA: Region, eval = T, include = T}
region_depression.lifetime <- select(cpes.cleaned, c("region", "depression.lifetime"))

region_Pop <- as.data.frame(table(region_depression.lifetime[,"region"])) %>% 
  rename(region = Var1) %>% 
  rename("population" = Freq)

uniqueRegions <- length(unique(region_depression.lifetime$region))
region_depressionPop.lifetime <- as.data.frame(
  table(region_depression.lifetime[region_depression.lifetime$depression.lifetime == '1',]))[1:uniqueRegions,] %>% 
  rename("endorsed" = Freq)

region_depression.lifetime <- cbind(region_Pop, region_depressionPop.lifetime$endorsed) %>% rename("endorsed" = "region_depressionPop.lifetime$endorsed") %>% mutate(rate = endorsed / population)

region_depression.lifetime <- region_depression.lifetime[region_depression.lifetime$population >= 30,]

region_depression.lifetime$region <- factor(region_depression.lifetime$region, 
                                           levels = unique(region_depression.lifetime$region)
                                           [order(region_depression.lifetime$rate, decreasing = F)])

regionDist.plot <- plot_ly(region_depression.lifetime, x = ~region, y = ~population, type = 'bar') %>% 
  layout(title = "Population by Region", xaxis = list(title = "Region"), yaxis = list(title = "Population", range = c(0, 8000)))
regionDist.plot

region_depression.lifetime.plot <- plot_ly(region_depression.lifetime, x = ~region, y = ~rate, type = 'bar') %>% 
  layout(title = "% Diagnosed with MDD by region (Lifetime)", xaxis = list(title = "Region"), yaxis = list(title = "% Diagnosed with MDD (Lifetime)", range = c(0,0.25)))
region_depression.lifetime.plot
```

The South appears to be over-represented in our sample. Though, that should not skew the depression rate measures in the second graph, in which the South appears to be the least depressed at 13% vs. the Midwest's 17%

<h2>Gender</h2>

```{r eda sex, eval = T, include = T}
sex_depression.lifetime <- select(cpes.cleaned, c("sex", "depression.lifetime"))

sex_Pop <- as.data.frame(table(sex_depression.lifetime[,"sex"])) %>% 
  rename(sex = Var1) %>% 
  rename("population" = Freq)

uniqueSexes <- length(unique(sex_depression.lifetime$sex))
sex_depressionPop.lifetime <- as.data.frame(
  table(sex_depression.lifetime[sex_depression.lifetime$depression.lifetime == '1',]))[1:uniqueSexes,] %>% 
  rename("endorsed" = Freq)

sex_depression.lifetime <- cbind(sex_Pop, sex_depressionPop.lifetime$endorsed) %>% rename("endorsed" = "sex_depressionPop.lifetime$endorsed") %>% mutate(rate = endorsed / population)

sex_depression.lifetime <- sex_depression.lifetime[sex_depression.lifetime$population >= 30,]

sex_depression.lifetime$sex <- factor(sex_depression.lifetime$sex, 
                                           levels = unique(sex_depression.lifetime$sex)
                                           [order(sex_depression.lifetime$rate, decreasing = F)])

sexDist.plot <- plot_ly(sex_depression.lifetime, x = ~sex, y = ~population, type = 'bar') %>% 
  layout(title = "Population by Sex", xaxis = list(title = "Sex"), yaxis = list(title = "Population", range = c(0, 13000)))
sexDist.plot

sex_depression.lifetime.plot <- plot_ly(sex_depression.lifetime, x = ~sex, y = ~rate, type = 'bar') %>% 
  layout(title = "% Diagnosed with MDD by Sex (Lifetime)", xaxis = list(title = "Sex"), yaxis = list(title = "% Diagnosed with MDD (Lifetime)", range = c(0,0.25)))
sex_depression.lifetime.plot
```

Females are over-represented in our sample. They also have a higher depression rate at 16.9% compared to 10.5% for males

<h2>Age</h2>

```{r eda age, eval = F, include = T}
age_depression.12Month <- select(cpes.cleaned, c("age", "depression.12Month"))

age_Pop <- as.data.frame(table(age_depression.12Month[,"age"])) %>% 
  rename(age = Var1) %>% 
  rename("population" = Freq)

uniqueAges <- length(unique(age_depression.12Month$age))
age_depressionPop.12Month <- as.data.frame(
  table(age_depression.12Month[age_depression.12Month$depression.12Month == '1',]))[1:uniqueAges,] %>% 
  rename("endorsed" = Freq)

age_depression.12Month <- cbind(age_Pop, age_depressionPop.12Month$endorsed) %>% rename("endorsed" = "age_depressionPop.12Month$endorsed") %>% mutate(rate = endorsed / population)

ageDist.plot <- plot_ly(age_depression.12Month, x = ~age, y = ~population, type = 'bar') %>% 
  layout(title = "Population by Age", xaxis = list(title = "Age"), yaxis = list(title = "Population", range = c(0, 500)))
ageDist.plot

age_depression.12Month <- age_depression.12Month[age_depression.12Month$population >= 30,]
age_depression.12Month %<>% mutate_at(c("age"), as.numeric)
age_depression.12Month <- mutate(age_depression.12Month, age = age + 17)
age_depression.12Month.fit <- lm(rate~age, data = age_depression.12Month)

age_depression.12Month.plot <- plot_ly(age_depression.12Month, x = ~age, y = ~rate, type = 'scatter', mode = 'markers') %>% 
  layout(title = "% Positive for MDD by Age (12Month)",
         xaxis = list(title = "Age"), 
         yaxis = list(title = "% Positive for MDD (12Month)", range = c(0,0.25))) %>%
  add_trace(x = ~age, y = fitted(age_depression.12Month.fit), mode = 'lines')
age_depression.12Month.plot
summary(age_depression.12Month.fit)
```

The age distribution matches that of the United States. For the graph of depression rates, ages from 87 to 99 were excluded, as they had less than 30 observations. Depression rate appears to generally trend downward as age increases.

<h2>Race</h2>

```{r eda race, eval = F, include = T}
race_depression.lifetime <- select(cpes.cleaned, c("race", "depression.lifetime"))

race_Pop <- as.data.frame(table(race_depression.lifetime[,"race"])) %>% 
  rename(race = Var1) %>% 
  rename("population" = Freq)

uniqueraces <- length(unique(race_depression.lifetime$race))
race_depressionPop.lifetime <- as.data.frame(
  table(race_depression.lifetime[race_depression.lifetime$depression.lifetime == '1',]))[1:uniqueraces,] %>% 
  rename("endorsed" = Freq)

race_depression.lifetime <- cbind(race_Pop, race_depressionPop.lifetime$endorsed) %>% rename("endorsed" = "race_depressionPop.lifetime$endorsed") %>% mutate(rate = endorsed / population)

race_depression.lifetime <- race_depression.lifetime[race_depression.lifetime$population >= 30,]

race_depression.lifetime$race <- factor(race_depression.lifetime$race, 
                                           levels = unique(race_depression.lifetime$race)
                                           [order(race_depression.lifetime$rate, decreasing = F)])

raceDist.plot <- plot_ly(race_depression.lifetime, x = ~race, y = ~population, type = 'bar') %>% 
  layout(title = "Population by Race", xaxis = list(title = "Race"), yaxis = list(title = "Population", range = c(0, 8000)))
raceDist.plot

race_depression.lifetime.plot <- plot_ly(race_depression.lifetime, x = ~race, y = ~rate, type = 'bar') %>% 
  layout(title = "% Diagnosed with MDD by Race (Lifetime)", xaxis = list(title = "Race"), yaxis = list(title = "% Diagnosed with MDD (Lifetime)", range = c(0,0.25)))
race_depression.lifetime.plot
```

The race distribution generally matches that of the United States. Depression rate appears to be the highest for "All Other" Minorities, Non-Hispanic Whites, and Puerto Ricans.

<h2>Household Income</h2>

```{r eda householdIncome, eval = F, include = T}
householdIncome_depression.12Month <- select(cpes.cleaned, c("householdIncome", "depression.12Month"))

householdIncome_depression.12Month <- mutate(householdIncome_depression.12Month, householdIncome = round_any(householdIncome, 5000, f = floor))

householdIncome_Pop <- as.data.frame(table(householdIncome_depression.12Month[,"householdIncome"])) %>% 
  rename(householdIncome = Var1) %>% 
  rename("population" = Freq)

uniquehouseholdIncomes <- length(unique(householdIncome_depression.12Month$householdIncome)) - 1
householdIncome_depressionPop.12Month <- as.data.frame(
  table(householdIncome_depression.12Month[householdIncome_depression.12Month$depression.12Month == '1',]))[1:uniquehouseholdIncomes,] %>% 
  rename("endorsed" = Freq)

householdIncome_depression.12Month <- cbind(householdIncome_Pop, householdIncome_depressionPop.12Month$endorsed) %>% rename("endorsed" = "householdIncome_depressionPop.12Month$endorsed") %>% mutate(rate = endorsed / population)

householdIncomeDist.plot <- plot_ly(householdIncome_depression.12Month, x = ~householdIncome, y = ~population, type = 'bar') %>% 
  layout(
    title = "Population by Household Income",
    xaxis = list(title = "Household Income"),
    yaxis = list(title = "Population", range = c(0, 1500)))
householdIncomeDist.plot

householdIncome_depression.12Month <- householdIncome_depression.12Month[householdIncome_depression.12Month$population >= 60,]
householdIncome_depression.12Month %<>% mutate_at(c("householdIncome"), as.numeric)
householdIncome_depression.12Month <- mutate(householdIncome_depression.12Month, householdIncome = 5000*householdIncome + 5000)
householdIncome_depression.12Month.fit <- lm(rate~householdIncome, data = householdIncome_depression.12Month)

householdIncome_depression.12Month.plot <- plot_ly(householdIncome_depression.12Month, x = ~householdIncome, y = ~rate, type = 'scatter', mode = 'markers') %>% 
  layout(title = "% Positive for MDD by Household Income (12Month)",
         xaxis = list(title = "Household Income"), 
         yaxis = list(title = "% Positive for MDD (12Month)", range = c(0,0.25))) %>%
  add_trace(x = ~householdIncome, y = fitted(householdIncome_depression.12Month.fit), mode = 'lines')
householdIncome_depression.12Month.plot

summary(householdIncome_depression.12Month.fit)
```

Income distribution appears to generally follow that of the United States, though our model has income capped at 200,000. Incomes have also been rounded to the nearest floor by increments of 5000, and observations of less than 30 have been omitted. Depression rate generally decreases from 10k to 100k, increases from 100k to 145k, drops at 150k, and remains steady afterward, with perhaps a slight increase.

<h2>Employment</h2>

```{r eda employment, eval = F, include = T}
employment.current_depression.lifetime <- select(cpes.cleaned, c("employment.current", "depression.lifetime"))

employment.current_Pop <- as.data.frame(table(employment.current_depression.lifetime[,"employment.current"])) %>% 
  rename(employment.current = Var1) %>% 
  rename("population" = Freq)

uniqueemployment.currents <- length(unique(employment.current_depression.lifetime$employment.current)) - 1
employment.current_depressionPop.lifetime <- as.data.frame(
  table(employment.current_depression.lifetime[employment.current_depression.lifetime$depression.lifetime == '1',]))[1:uniqueemployment.currents,] %>% 
  rename("endorsed" = Freq)

employment.current_depression.lifetime <- cbind(employment.current_Pop, employment.current_depressionPop.lifetime$endorsed) %>% rename("endorsed" = "employment.current_depressionPop.lifetime$endorsed") %>% mutate(rate = endorsed / population)

employment.current_depression.lifetime <- employment.current_depression.lifetime[employment.current_depression.lifetime$population >= 30,]

employment.current_depression.lifetime$employment.current <- factor(employment.current_depression.lifetime$employment.current, 
                                           levels = unique(employment.current_depression.lifetime$employment.current)
                                           [order(employment.current_depression.lifetime$rate, decreasing = F)])

employment.currentDist.plot <- plot_ly(employment.current_depression.lifetime, x = ~employment.current, y = ~population, type = 'bar') %>% 
  layout(title = "Population by employment.current", xaxis = list(title = "employment.current"), yaxis = list(title = "Population", range = c(0, 15000)))
employment.currentDist.plot

employment.current_depression.lifetime.plot <- plot_ly(employment.current_depression.lifetime, x = ~employment.current, y = ~rate, type = 'bar') %>% 
  layout(title = "% Diagnosed with MDD by employment.current (Lifetime)", xaxis = list(title = "employment.current"), yaxis = list(title = "% Diagnosed with MDD (Lifetime)", range = c(0,0.25)))
employment.current_depression.lifetime.plot
```

Employment distribution generally resembles that of the United States, save for a slightly higher than expected rate of respondents not in the labor force. Employment appears to lower depression rates, as "Not in Labor Force" and "Unemployed" groups have the highest depression rates.

<h2>Education</h2>

```{r eda education, eval = F, include = T}
yearsOfEducation.respondent_depression.lifetime <- select(cpes.cleaned, c("yearsOfEducation.respondent", "depression.lifetime", "age"))

yearsOfEducation.respondent_depression.lifetime <- yearsOfEducation.respondent_depression.lifetime[yearsOfEducation.respondent_depression.lifetime$age > 23,] %>% 
  select(-c("age"))

yearsOfEducation.respondent_Pop <- as.data.frame(table(yearsOfEducation.respondent_depression.lifetime[,"yearsOfEducation.respondent"])) %>% 
  rename(yearsOfEducation.respondent = Var1) %>% 
  rename("population" = Freq)

uniqueyearsOfEducation.respondents <- length(unique(yearsOfEducation.respondent_depression.lifetime$yearsOfEducation.respondent)) - 1
yearsOfEducation.respondent_depressionPop.lifetime <- as.data.frame(
  table(yearsOfEducation.respondent_depression.lifetime[yearsOfEducation.respondent_depression.lifetime$depression.lifetime == '1',]))[1:uniqueyearsOfEducation.respondents,] %>% 
  rename("endorsed" = Freq)

yearsOfEducation.respondent_depression.lifetime <- cbind(yearsOfEducation.respondent_Pop, yearsOfEducation.respondent_depressionPop.lifetime$endorsed) %>% rename("endorsed" = "yearsOfEducation.respondent_depressionPop.lifetime$endorsed") %>% mutate(rate = endorsed / population)

yearsOfEducation.respondentDist.plot <- plot_ly(yearsOfEducation.respondent_depression.lifetime, x = ~yearsOfEducation.respondent, y = ~population, type = 'bar') %>% 
  layout(
    title = "Population by Years of Education",
    xaxis = list(title = "Years of Education"),
    yaxis = list(title = "Population", range = c(0, 6000)))
yearsOfEducation.respondentDist.plot

yearsOfEducation.respondent_depression.lifetime <- yearsOfEducation.respondent_depression.lifetime[yearsOfEducation.respondent_depression.lifetime$population >= 60,]
yearsOfEducation.respondent_depression.lifetime %<>% mutate_at(c("yearsOfEducation.respondent"), as.numeric)
yearsOfEducation.respondent_depression.lifetime <- mutate(yearsOfEducation.respondent_depression.lifetime, yearsOfEducation.respondent = yearsOfEducation.respondent + 3)
yearsOfEducation.respondent_depression.lifetime.fit <- lm(rate~yearsOfEducation.respondent, data = yearsOfEducation.respondent_depression.lifetime)

yearsOfEducation.respondent_depression.lifetime.plot <- plot_ly(yearsOfEducation.respondent_depression.lifetime, x = ~yearsOfEducation.respondent, y = ~rate, type = 'scatter', mode = 'markers') %>% 
  layout(title = "% Diagnosed with MDD by Years of Education (lifetime)",
         xaxis = list(title = "Years of Education"), 
         yaxis = list(title = "% Diagnosed with MDD (lifetime)", range = c(0,0.25))) %>%
  add_trace(x = ~yearsOfEducation.respondent, y = fitted(yearsOfEducation.respondent_depression.lifetime.fit), mode = 'lines')
yearsOfEducation.respondent_depression.lifetime.plot

summary(yearsOfEducation.respondent_depression.lifetime.fit)
```

The education distribution is as expected, and representative of the United States, with an expected peak at 12 years. To plot depression rates, respondents of less than 23 years of age were excluded for the purpose of modeling lifetime risk of depression. Save for a peak at 4 years of education, depression rates generally trend upwards as people get more educated, until it plateaus at around 13.

<h2>Pairwise</h2>

```{r eda pairwise, eval = T, include = T, fig.height=54, fig.width=96}
pairs.panels(cont[2:27])
#TODO: Exclude depression variables
```

Pairwise plot of all continuous variables. High level assessment for multicollinearity, and potential interesting relationships between variables.

<h1> Assessing 30 day Risk Of Testing Positive for MDD </h1>

All predictive modeling techniques below will use the same testing set (NAs omitted) to determine MCE, Sensitivity, and Specificity. Training sets will be modified accordingly as not all models natively handle NAs. Via random sampling, all training sets are balanced to ensure an about equal distribution of endorsed and not endorsed observations. This is to prevent the model learning to predict consistently "not endorsed" without proper consideration of feature values, as our data is heavily skewed in that manner. The base training and testing set however, is made of a 65:20 split of all observations where 30 day depression endorsement is valid. The remaining 15 are allocated to a validation set for final model comparison.

Variables of interest relevant to a 30 day prediction are: *physicalHealth* *socialLifeDifficulty*, *healthWorkAbsence*, difficultyRemembering,  daysMobilityDifficult, daysOvertime, difficultyConcentrating, difficultyUnderstandingSituation, and jobPerformance.

Bolded variables have a missingness of less than 60%

<h2>Null Model</h2>
Assume MCE = 50%, Sensitivity: 50%, Specificity: 50%

<h2>Single Tree</h2>
```{r tree 30day,  eval = T, include = T}
data <- select(cpes.cleaned, c("physicalHealth.30day", "difficultyConcentrating.30day", "difficultyUnderstandingSituation.30day", "socialLifeDifficulty.30day", "difficutlyRemembering.30day", "healthWorkAbsence.30day", "daysMobilityDifficult.30day", "daysOvertime.30day", "jobPerformance.30day"))

levels(data$disorder.30day) <- list('1' = "Endorsed", '0' = "Not Endorsed")

#Save unimputed data
if (file.exists("data/30dayData_unimputed.Rda")) {
  file.remove("data/30dayData_unimputed.Rda")
}
saveRDS(data, file = "data/30dayData_unimputed.Rda")

#Create and save imputed data
set.seed(100)
data.imputed <- rfImpute(disorder.30day~., data = data)
if (file.exists("data/30dayData_imputed.Rda")) {
  file.remove("data/30dayData_imputed.Rda")
}
saveRDS(data.imputed, file = "data/30dayData_imputed.Rda")

#Create ind: index used to create training and test sets
set.seed(101)
ind <- sample(3, nrow(data), replace = T, prob = c(0.65, 0.2, 0.15))

#Prepare unimputed sets
train <- data[ind == 1,]
if (file.exists("data/30dayTrain_unimputed.Rda")) {
  file.remove("data/30dayTrain_unimputed.Rda")
}
saveRDS(train, file = "data/30dayTrain_unimputed.Rda")
testOne <- data[ind == 2,]
if (file.exists("data/30dayTestOne_unimputed.Rda")) {
  file.remove("data/30dayTestOne_unimputed.Rda")
}
saveRDS(testOne, file = "data/30dayTestOne_unimputed.Rda")
testTwo <- data[ind == 3,]
if (file.exists("data/30dayTestTwo_unimputed.Rda")) {
  file.remove("data/30dayTestTwo_unimputed.Rda")
}
saveRDS(testTwo, file = "data/30dayTestTwo_unimputed.Rda")

#Prepare imputed sets
train <- data.imputed[ind == 1,]
if (file.exists("data/30dayTrain_imputed.Rda")) {
  file.remove("data/30dayTrain_imputed.Rda")
}
saveRDS(train, file = "data/30dayTrain_imputed.Rda")

testOne <- data.imputed[ind == 2,]
if (file.exists("data/30dayTestOne_imputed.Rda")) {
  file.remove("data/30dayTestOne_imputed.Rda")
}
saveRDS(testOne, file = "data/30dayTestOne_imputed.Rda")

testTwo <- data.imputed[ind == 3,]
if (file.exists("data/30dayTestTwo_imputed.Rda")) {
  file.remove("data/30dayTestTwo_imputed.Rda")
}
saveRDS(testTwo, file = "data/30dayTestTwo_imputed.Rda")

# Imputed (Initial)
# Accuracy : 0.772         
# Sensitivity : 0.6029        
# Specificity : 0.7758  

# Imputed (First Iteration)
# Accuracy : 0.78         
# Sensitivity : 0.588        
# Specificity : 0.784  

# Imputed (Second Iteration)
# Accuracy : 0.83         
# Sensitivity : 0.573        
# Specificity : 0.835

# Imputed (Third Iteration)
# Accuracy : 0.828         
# Sensitivity : 0.6029        
# Specificity : 0.8328

# Imputed (Fourth Iteration)
# Accuracy : 0.828         
# Sensitivity : 0.6029        
# Specificity : 0.8328

# Imputed (Fifth Iteration) OPTIMAL
# Accuracy : 0.828         
# Sensitivity : 0.6029        
# Specificity : 0.8331

# Imputed (Sixth Iteration)
# Accuracy : 0.834        
# Sensitivity : 0.5882       
# Specificity : 0.8395

# Imputed (Seventh Iteration)
# Accuracy : 0.892    
# Sensitivity : 0.4706       
# Specificity : 0.9015

# Imputed (Eighth Iteration)
# Accuracy : 0.913
# Sensitivity : 0.35294       
# Specificity : 0.92527
train <- readRDS("data/30dayTrain_imputed.Rda")

# Unimputed (initial)
# Accuracy : 0.72          
# Sensitivity : 0.7353        
# Specificity : 0.7198  
# train <- readRDS("data/30dayTrain_unimputed.Rda")

train.endorsed <- train[train$disorder.30day == "1",]
train.notEndorsed <- train[train$disorder.30day == "0",]
prob <- nrow(train.endorsed)/nrow(train.notEndorsed)
set.seed(99)
ind <- sample(2, nrow(train.notEndorsed), replace = T, prob = c(prob, 1-prob))
train.notEndorsed <- train.notEndorsed[ind == 1,]
train.balanced <- rbind(train.notEndorsed, train.endorsed)

testOne <- readRDS("data/30dayTestOne_unimputed.Rda")

tree.fit <- rpart(disorder.30day~., data = train.balanced, method = "class")
tree.fit.pred <- predict(tree.fit, testOne, type = "class")
confusionMatrix(tree.fit.pred, testOne$disorder.30day)
tree.fit$variable.importance[order(tree.fit$variable.importance)]

train.balanced.iter1 <- select(train.balanced, -c("jobPerformance.30day"))
tree.fit.iter1 <- rpart(disorder.30day~., data = train.balanced.iter1, method = "class")
tree.fit.iter1.pred <- predict(tree.fit.iter1, testOne, type = "class")
confusionMatrix(tree.fit.iter1.pred, testOne$disorder.30day)
tree.fit.iter1$variable.importance[order(tree.fit.iter1$variable.importance)]

train.balanced.iter2 <- select(train.balanced, -c("jobPerformance.30day", "daysMobilityDifficult.30day"))
tree.fit.iter2 <- rpart(disorder.30day~., data = train.balanced.iter2, method = "class")
tree.fit.iter2.pred <- predict(tree.fit.iter2, testOne, type = "class")
confusionMatrix(tree.fit.iter2.pred, testOne$disorder.30day)
tree.fit.iter2$variable.importance[order(tree.fit.iter2$variable.importance)]

train.balanced.iter3 <- select(train.balanced, -c("jobPerformance.30day", "daysMobilityDifficult.30day", "daysOvertime.30day"))
tree.fit.iter3 <- rpart(disorder.30day~., data = train.balanced.iter3, method = "class")
tree.fit.iter3.pred <- predict(tree.fit.iter3, testOne, type = "class")
confusionMatrix(tree.fit.iter3.pred, testOne$disorder.30day)
tree.fit.iter3$variable.importance[order(tree.fit.iter3$variable.importance)]

train.balanced.iter4 <- select(train.balanced, -c("daysOvertime.30day", "jobPerformance.30day", "daysMobilityDifficult.30day", "physicalHealth.30day"))
tree.fit.iter4 <- rpart(disorder.30day~., data = train.balanced.iter4, method = "class")
tree.fit.iter4.pred <- predict(tree.fit.iter4, testOne, type = "class")
confusionMatrix(tree.fit.iter4.pred, testOne$disorder.30day)
tree.fit.iter4$variable.importance[order(tree.fit.iter4$variable.importance)]

train.balanced.iter5 <- select(train.balanced, -c("daysOvertime.30day", "jobPerformance.30day", "daysMobilityDifficult.30day", "physicalHealth.30day", "difficultyConcentrating.30day"))
tree.fit.iter5 <- rpart(disorder.30day~., data = train.balanced.iter5, method = "class")
tree.fit.iter5.pred <- predict(tree.fit.iter5, testOne, type = "class")
confusionMatrix(tree.fit.iter5.pred, testOne$disorder.30day)
tree.fit.iter5$variable.importance[order(tree.fit.iter5$variable.importance)]

train.balanced.iter6 <- select(train.balanced, -c("daysOvertime.30day", "jobPerformance.30day", "daysMobilityDifficult.30day", "physicalHealth.30day", "difficultyConcentrating.30day", "difficutlyRemembering.30day"))
tree.fit.iter6 <- rpart(disorder.30day~., data = train.balanced.iter6, method = "class")
tree.fit.iter6.pred <- predict(tree.fit.iter6, testOne, type = "class")
confusionMatrix(tree.fit.iter6.pred, testOne$disorder.30day)
tree.fit.iter6$variable.importance[order(tree.fit.iter6$variable.importance)]

train.balanced.iter7 <- select(train.balanced, -c("daysOvertime.30day", "jobPerformance.30day", "daysMobilityDifficult.30day", "physicalHealth.30day", "difficultyConcentrating.30day", "difficutlyRemembering.30day", "healthWorkAbsence.30day"))
tree.fit.iter7 <- rpart(disorder.30day~., data = train.balanced.iter7, method = "class")
tree.fit.iter7.pred <- predict(tree.fit.iter7, testOne, type = "class")
confusionMatrix(tree.fit.iter7.pred, testOne$disorder.30day)
tree.fit.iter7$variable.importance[order(tree.fit.iter7$variable.importance)]

train.balanced.iter8 <- select(train.balanced, -c("daysOvertime.30day", "jobPerformance.30day", "daysMobilityDifficult.30day", "physicalHealth.30day", "difficultyConcentrating.30day", "difficutlyRemembering.30day", "healthWorkAbsence.30day", "difficultyUnderstandingSituation.30day"))
tree.fit.iter8 <- rpart(disorder.30day~., data = train.balanced.iter8, method = "class")
tree.fit.iter8.pred <- predict(tree.fit.iter8, testOne, type = "class")
confusionMatrix(tree.fit.iter8.pred, testOne$disorder.30day)
tree.fit.iter8$variable.importance[order(tree.fit.iter8$variable.importance)]

tree.fit.iter5$variable.importance
rpart.plot(tree.fit.iter5)
```

We identify our optimal tree as the one with the lowest overall MCE while maintaining a high Sensitivity and Specificity. Trees were trained on two versions of the training set, imputed and unimputed. Missing values in the imputed training set were imputed using rfImpute from the randomForest package. Our best tree was iteration 5 of the imputed training set, with MCE = 0.172, Sensitivity = 0.6029, Specificity = 0.8331, and important variables socialLifeDifficulty, difficultyUnderstandingSituation, healthWorkAbsence, and difficultyRemembering (ordered from most to least important)

<h2>Random Forest</h2>

Forests were grown from preimputed (rfImpute performed on entire dataset of interest variables, training set was then selected from imputed dataset), postimputed (rfImpute performed on training set selected from dataset still with NAs), and unimputed training sets (randomForest cannot handle NAs, so NAs were omitted for unimputed training sets). Additionally, the procedures were repeated for two sets of variables: "allVars" and "goodVars". "allVars" contains all 9 variables of interest, while "goodVars" contains only the ones with missingness below 60%.

Once more, we identify our optimal forest as the one with the lowest overall MCE while maintaining a high Sensitivity and Specificity.


#Best True Positive Rate, Horrible Overall Accuracy/MCE
```{r rfSetup: allVars preimputed, eval = T}
train <- readRDS("data/30dayTrain_imputed.Rda")

testOne <- na.omit(readRDS("data/30dayTestOne_unimputed.Rda"))

# Optimal mtry: 6
# OOB Error: 32.8%
# Sensitivity : 0.833         
# Specificity : 0.25 
# Accuracy : 0.326
```

#Postimputed Best Balance
```{r rfSetup: allVars postimputed/unimputed, eval = T}
train <- readRDS("data/30dayTrain_unimputed.Rda")
#Remove all rows with more "num" NAs. Set to 0 to do unimputed training
num <- 3
train <- train[(rowSums(is.na(train)) <= num),]
set.seed(102)
if(num != 0){
  train <- rfImpute(disorder.30day~., data = train) #Impute missing values
}

testOne <- na.omit(readRDS("data/30dayTestOne_unimputed.Rda"))

# Optimal num: 3
# Optimal mtry: 4
# OOB estimate of  error rate: 44.4%
# Accuracy: 0.63 
# Sensitivity: 0.667  
# Specificity: 0.625 

#Unimputed results in balanced training set of size 15
```

#Comparable to "Best Balance". Better True Negative, Worse True Positive. Tested on larger test set.
```{r rfSetup: goodVars preimputed, eval = T}
train <- readRDS("data/30dayTrain_imputed.Rda")
train <- select(train, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day"))

testOne <- readRDS("data/30dayTestOne_unimputed.Rda")
testOne <- na.omit(select(testOne, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day")))

# Optimal mtry: 2
# OOB estimate of  error rate: 30.9%
# Accuracy: 0.689  
# Sensitivity: 0.55  
# Specificity: 0.694
```

#Best True Negative Rate & Overall Accuracy
```{r rfSetup: goodVars postimputed/unimputed, eval = T}
train <- readRDS("data/30dayTrain_unimputed.Rda")
train <- select(train, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day"))
num <- 0 #Remove all rows with more "num" NAs. Set to 0 to do unimputed training
train <- train[(rowSums(is.na(train)) <= num),]
set.seed(103)
if(num != 0){
  train <- rfImpute(disorder.30day~., data = train)
}

testOne <- readRDS("data/30dayTestOne_unimputed.Rda")
testOne <- na.omit(select(testOne, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day")))

# Optimal num: 0 (Unimputed)
# Optimal mtry: 2
# OOB estimate of  error rate: 43%
# Accuracy: 0.843 
# Sensitivity: 0.475  
# Specificity: 0.857
```

```{r rfBody, eval = T}
################################################number of variables, 9 for allVars, 3 for goodVars
n <- 9

#Create balanced training set, where num endorsed ~ num not endorsed
train.endorsed <- train[train$disorder.30day == "1",]
train.notEndorsed <- train[train$disorder.30day == "0",]
prob <- nrow(train.endorsed)/nrow(train.notEndorsed)
set.seed(104)

ind <- sample(2, nrow(train.notEndorsed), replace = T, prob = c(prob, 1-prob))
train.notEndorsed <- train.notEndorsed[ind == 1,]
train.balanced <- rbind(train.notEndorsed, train.endorsed)

rf.error.p <- rep(0, n)
for (p in 1:n){
  rf.fit <- randomForest(disorder.30day~., data = train.balanced, ntree = 500, mtry = p)
  rf.error.p[p] <- rf.fit$err.rate[500]
}
plot(1:n, rf.error.p, pch=16,
     main = "OOB Error Rate for mtry With 500 Trees",
     xlab="mtry",
     ylab="OOB Error Rate")
lines(1:n, rf.error.p)

rf.error.p <- rep(0, n)
for (p in 1:n){
  rf.fit <- randomForest(disorder.30day~., data = train.balanced, ntree = 500, mtry = p)
  rf.fit.pred <- predict(rf.fit, testOne)
  rf.error.p[p] <- confusionMatrix(rf.fit.pred, testOne$disorder.30day)$byClass[1] #True Positive
}
plot(1:n, rf.error.p, pch=16,
     main = "TestOne True Positive Rate for mtry",
     xlab="mtry",
     ylab="True Positive Rate")
lines(1:n, rf.error.p)

rf.error.p <- rep(0, n)
for (p in 1:n){
  rf.fit <- randomForest(disorder.30day~., data = train.balanced, ntree = 500, mtry = p)
  rf.fit.pred <- predict(rf.fit, testOne)
  rf.error.p[p] <- confusionMatrix(rf.fit.pred, testOne$disorder.30day)$byClass[2] #True Negative
}
plot(1:n, rf.error.p, pch=16,
     main = "TestOne True Negative Rate for mtry",
     xlab="mtry",
     ylab="True Negative Rate")
lines(1:n, rf.error.p)

#Final Model
set.seed(105)
rf.fit <- randomForest(disorder.30day~., data = train.balanced, ntree = 500, mtry = 2, proximity = T) ########################Modify mtry
rf.fit
varImpPlot(rf.fit, sort=T, n.var=min(10, nrow(rf.fit$importance)))
hist(treesize(rf.fit), main = "No. of nodes", col = "blue")

#CANNOT HANDLE NA VALUES FOR FEATURES IN TEST SETS
rf.fit.pred <- predict(rf.fit, testOne)
confusionMatrix(rf.fit.pred, testOne$disorder.30day)$overall[1] #Accuracy
confusionMatrix(rf.fit.pred, testOne$disorder.30day)$byClass[1] #True Positive
confusionMatrix(rf.fit.pred, testOne$disorder.30day)$byClass[2] #True Negative

MDSplot(rf.fit, testOne$disorder.30day)
```

The best model was our postimputed forest with mtry = 4, and number of NAs allowed in training set before imputation set to 3: MCE = 44.4%, Sensitivity = 0.667, Specificity = 0.625. Ranked by importance according to mean decrease gini, the most important variables were daysMobilityDifficult, jobPerformance, and daysOvertime. For important variables, this appears to contradict our single tree model.

<h2>LASSO</h2>

Like randomForest, our LASSO function cannot handle NA values in either the testing or the training sets. LASSO algorithms will trained on preimputed, postimputed, and unimputed training sets for both "allVars" and "goodVars". The criterion for selecting optimal algorithm remains the same.

```{r lassoSetup: allVars preimputed, eval = T}
train <- readRDS("data/30dayTrain_imputed.Rda")
testOne <- na.omit(readRDS("data/30dayTestOne_unimputed.Rda"))

# Training Error: 0.27
# Testing Error: 0.152
# Testing Sensitivity: 0.333
# Testing Specificity: 0.884
#Optimal Threshold: 0.02
```

```{r lassoSetup: allVars postimputed/unimputed, eval = T}
train <- readRDS("data/30dayTrain_unimputed.Rda")
#Remove all rows with more than "num" NAs. Set to 0 to do unimputed training
num <- 3
train <- train[(rowSums(is.na(train)) <= num),]
if(num != 0){
  set.seed(107)
  train <- rfImpute(disorder.30day~., data = train) #Impute missing values
}

testOne <- na.omit(readRDS("data/30dayTestOne_unimputed.Rda"))

# [1] "Training Error"
# [1] 0.401
# [1] "Testing Error"
# [1] 0.109
# [1] "Testing Sensitivity"
# [1] 0.667
# [1] "Testing Specificity"
# [1] 0.907
# Optimal num: 3
# Optimal threshold: 0.48
```

```{r lassoSetup: goodVars preimputed, eval = T}
train <- readRDS("data/30dayTrain_imputed.Rda")
train <- select(train, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day"))

testOne <- readRDS("data/30dayTestOne_unimputed.Rda")
testOne <- na.omit(select(testOne, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day")))

# Training Error: 0.42
# Testing Error: 0.0466
# Testing Sensitivity: 0.167
# Testing Specificity: 0.966
# Optimal Threshold: 0.38
```

```{r lassoSetup: goodVars postimputed/unimputed, eval = T}
train <- readRDS("data/30dayTrain_unimputed.Rda")
train <- select(train, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day"))
num <- 2 #Remove all rows with more "num" NAs. Set to 0 to do unimputed training
train <- train[(rowSums(is.na(train)) <= num),]
set.seed(108)
if(num != 0){
  train <- rfImpute(disorder.30day~., data = train)
}

testOne <- readRDS("data/30dayTestOne_unimputed.Rda")
testOne <- na.omit(select(testOne, c("physicalHealth.30day", "socialLifeDifficulty.30day", "healthWorkAbsence.30day", "disorder.30day")))

# Optimal num: 0 (Unimputed)
# Training Error: 43%
# Testing Error: 0.0618 
# Sensitivity: 0.128  
# Specificity: 0.968
# Optimal Threshold: 0.38
```

```{r lasso body, eval = T}
#Pairwise plot of numeric features. Testing for collinearity. Active only for allVars
# pairs.panels(train[c(-1, -2, -3, -4, -5, -6, -10)])

#Form balanced training data
train.endorsed <- train[train$disorder.30day == "1",]
train.notEndorsed <- train[train$disorder.30day == "0",]
prob <- nrow(train.endorsed)/nrow(train.notEndorsed)
set.seed(109)
ind <- sample(2, nrow(train.notEndorsed), replace = T, prob = c(prob, 1-prob))
train.notEndorsed <- train.notEndorsed[ind == 1,]
train.balanced <- rbind(train.notEndorsed, train.endorsed)

# Specify vars - allVars: 1, goodVars: 4
varType <- 1 #######################################################################MODIFY!

#Isolate target
ytrain <- train.balanced[, varType]
#Isolate features
xtrain <- model.matrix(disorder.30day~., data = train.balanced)[, -varType]

#Try different lambda values
set.seed(110)
CV = cv.glmnet(x = xtrain, y = ytrain, family = "binomial", type.measure = "class", nfolds = 5, alpha = 1, nlambda = 100)
#Train lasso using previously identified optimal lambda
set.seed(111)
lasso.fit <- glmnet(x = xtrain, y = ytrain, family = "binomial", nfolds = 5, alpha = 1, lambda = CV$lambda.min)

#Plot Cross Validation for visualization
plot(CV)

lasso.fit.pred <- predict(lasso.fit, model.matrix(disorder.30day~., data = train.balanced)[, -1], type = "class")
predictions <- as.data.frame(lasso.fit.pred) %>% rename("predicted" = s0)
actual <- as.data.frame(train.balanced$disorder.30day) %>% rename("actual" = 'train.balanced$disorder.30day')
confusionMatrix <- as.data.frame(table(cbind(actual, predictions)))
oobError <- 1 - sum(confusionMatrix[confusionMatrix$actual == confusionMatrix$predicted, confusionMatrix$actual == confusionMatrix$predicted]$Freq) /
  sum(confusionMatrix$Freq)
###OOB ERROR
print("Training Error")
oobError

#Use lasso to predict target using features from testOne
toTest <- testOne ######################################################################################################MODIFY!
features <- model.matrix(disorder.30day~., data = toTest)[, -varType]
lasso.fit.pred <- predict(lasso.fit, features, type = "response")

#Visualize logistic regression probabilities
plot(lasso.fit.pred)

#Tuning
thresholdTests <- data.frame(matrix(0, nrow = 4, ncol = 100))
row.names(thresholdTests) <- c("threshold", "accuracy", "sensitivity", "specificity")

for(i in as.integer(100*min(lasso.fit.pred)+1):as.integer(100*max(lasso.fit.pred)-1))
{
  threshold <- i/100
  lasso.fit.testPred <- ifelse(lasso.fit.pred > threshold, "0", "1")
  predictions <- as.data.frame(lasso.fit.testPred) %>% rename("predicted" = s0)
  actual <- as.data.frame(toTest$disorder.30day) %>% rename("actual" = 'toTest$disorder.30day')
  confusionMatrix <- as.data.frame(table(cbind(actual, predictions)))
  thresholdTests[1,i] <- threshold
  thresholdTests[2,i] <- sum(confusionMatrix[confusionMatrix$actual == confusionMatrix$predicted, confusionMatrix$actual == confusionMatrix$predicted]$Freq) /
    sum(confusionMatrix$Freq)
  thresholdTests[3,i] <- confusionMatrix[confusionMatrix$actual == 1 & confusionMatrix$predicted == 1,]$Freq /
    sum(confusionMatrix[confusionMatrix$predicted == 1,]$Freq)
  thresholdTests[4,i] <- confusionMatrix[confusionMatrix$actual == 0 & confusionMatrix$predicted == 0,]$Freq /
    sum(confusionMatrix[confusionMatrix$predicted == 0,]$Freq)
}

length <- as.integer(100*max(lasso.fit.pred)-1) - as.integer(100*min(lasso.fit.pred)+1) + 1
thresholdVec <- rep(0, length)
accuracyVec <- rep(0, length)
sensitivityVec <- rep(0, length)
specificityVec <- rep(0, length)
for(i in 1:length)
{
  thresholdVec[i] <- thresholdTests[1,i+as.integer(100*min(lasso.fit.pred)+1)-2]
  accuracyVec[i] <- thresholdTests[2,i+as.integer(100*min(lasso.fit.pred)+1)-2]
  sensitivityVec[i] <- thresholdTests[3,i+as.integer(100*min(lasso.fit.pred)+1)-2]
  specificityVec[i] <- thresholdTests[4,i+as.integer(100*min(lasso.fit.pred)+1)-2]
}

threshold.dat <- data.frame("threshold" = thresholdVec, "accuracy" = accuracyVec, "sensitivity" = sensitivityVec, "specificity" = specificityVec)

thresholds.graph <- plot_ly(threshold.dat, x = ~threshold, y = ~accuracy, type = 'scatter', mode = 'lines', name = "accuracy") %>% 
  add_trace(x = ~threshold, y = ~sensitivity, type = 'scatter', mode = 'lines', name = "sensitivity") %>%
  add_trace(x = ~threshold, y = ~specificity, type = 'scatter', mode = 'lines', name = "specificity") %>%
  layout(title = "testOne accuracy measures vs threshold", xaxis = list(title = "threshold"), yaxis = list(title = "accuracy"))
thresholds.graph

#Note: Lasso appears to be calculating probability for not endorsed
lasso.fit.pred <- ifelse(lasso.fit.pred > 0.48, "0", "1") ##########################################################################MODIFY!
plot(lasso.fit.pred)

predictions <- as.data.frame(lasso.fit.pred) %>% rename("predicted" = s0)
actual <- as.data.frame(toTest$disorder.30day) %>% rename("actual" = 'toTest$disorder.30day')
confusionMatrix <- as.data.frame(table(cbind(actual, predictions)))
mce <- 1 - sum(confusionMatrix[confusionMatrix$actual == confusionMatrix$predicted, confusionMatrix$actual == confusionMatrix$predicted]$Freq) /
  sum(confusionMatrix$Freq)
sensitivity <- confusionMatrix[confusionMatrix$actual == 1 & confusionMatrix$predicted == 1,]$Freq / 
  sum(confusionMatrix[confusionMatrix$predicted == 1,]$Freq)
specificity <- confusionMatrix[confusionMatrix$actual == 0 & confusionMatrix$predicted == 0,]$Freq / 
  sum(confusionMatrix[confusionMatrix$predicted == 0,]$Freq)

print("Testing Error")
mce
print("Testing Sensitivity")
sensitivity
print("Testing Specificity")
specificity
lasso.fit$beta
```

The optimal algorithm was our LASSO trained on a allVars postimputed training set, where initial NAs allowed per row was set to 3 and threshold was set to 0.48: MCE = 0.109, Sensitivity = 0.667, Specificity = 0.907. difficultyUnderstandingSituation, socialLifeDifficulty, and healthWorkAbsence had non-zero coefficients in the model

<h2>boosting</h2>
```{r boosting 30day, eval = T}
train <- readRDS("data/30dayTrain_imputed.Rda")
testOne <- na.omit(readRDS("data/30dayTestOne_unimputed.Rda"))
train <- train[,c(10, 1:9)]

trainm <- sparse.model.matrix(disorder.30day~.-1, data = train)
train_label <- train[,"disorder.30day"]
train_matrix <- xgb.DMatrix(data = as.matrix(trainm), label = train_label)

testm <- trainm <- sparse.model.matrix(disorder.30day~.-1, data = testOne)
```

<h2>deep learning</h2>
```{r deep learning 30day, eval = T}

```

<h2>k nearest neighbor</h2>
```{r k nearest neighbor, eval = T}

```

<h2>naive bayes</h2>
```{r naive bayes, eval = T}

```

<h1>Variable Documentation (TODO)</h1>

Sources:
https://www.icpsr.umich.edu/web/ICPSR/studies/20240/summary (Publicly Available Dataset Download)
https://www.icpsr.umich.edu/web/DSDR/search/variables?q=yescount&STUDYQ=20240 (Variable Documentation)

&nbsp;
<hr />
<p style="text-align: center;">Alexander Chen</p>
<p style="text-align: center;">With A Very Special Thanks To Prof. Linda Zhao</p>
<p style="text-align: center;"><span style="color: #808080;"><em>alchen22@mlschools.org</em></span></p>
&nbsp;